output:
  format: "json" # Maybe add option for pickle?
  dir: "./output/"
  file: "output.json"
warmup: True
warmup_options:
  requests: 11
  timeout_sec: 20
storage: # TODO
  type: local
dataset:
  file: "datasets/openorca_large_subset_011.jsonl"
  max_queries: 1000
  min_input_tokens: 0
  max_input_tokens: 1024
  max_output_tokens: 256
  max_sequence_tokens: 1024
load_options:
  type: constant #Future options: loadgen, stair-step
  concurrency: 2
  duration: 20 # In seconds. Maybe in future support "100s" "10m", etc...
plugin: "azure_maap_plugin"
plugin_options:
  url: "https://phi-3-mini-128k-instruct-7.eastus2.inference.ml.azure.com/score"
  key: ""
  deployment: "phi-3-mini-128k-instruct-7"

  #interface: "grpc" # Some plugins like caikit-nlp-client should support grpc/http
  
extra_metadata:
  replicas: 1
